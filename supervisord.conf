[supervisord]
nodaemon=true
user=root

[program:fbq]
command=filebrowser -r /workspace -p 8080 --noauth
autorestart=true

[program:llama_router]
# This process is toggled by the Dashboard
command=python3 -m llama_cpp.server --models_dir /workspace/models --host 0.0.0.0 --port 5001 --n_gpu_layers -1
autorestart=true

[program:vlm_ui]
directory=/app/vlm-caption
command=python3 app.py --port 5002 --host 0.0.0.0
autorestart=true

[program:ostris_gui]
directory=/app/ai-toolkit
command=python3 webui.py --port 7860
autorestart=true

[program:coordinator]
command=python3 /app/scripts/coordinator.py
autorestart=true