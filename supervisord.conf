[supervisord]
nodaemon=true
user=root

[program:nginx]
command=/usr/sbin/nginx -g "daemon off;"
autorestart=true

[program:fbq]
environment=FILEBROWSER_CONFIG="/app/filebrowser.yaml"
command=filebrowser
autorestart=true
stdout_logfile=/var/log/fbq.log
stderr_logfile=/var/log/fbq.log
stdout_logfile_maxbytes=1MB

[program:llama_router]
# Toggled by the Dashboard - do NOT autostart
command=python3 -m llama_cpp.server --models_dir /workspace/models --host 0.0.0.0 --port 5001 --n_gpu_layers -1
autostart=false
autorestart=false

[program:vlm_ui]
directory=/app/vlm-caption
# --host is hardcoded in app.py; only --port is accepted
command=python3 app.py --port 5002
autorestart=true

[program:ostris_gui]
directory=/app/ai-toolkit/ui
# Real AI Toolkit UI - Node.js app on port 8675
command=npm run build_and_start
autorestart=true
stdout_logfile=/var/log/ostris_gui.log
stderr_logfile=/var/log/ostris_gui.log
stdout_logfile_maxbytes=1MB

[program:coordinator]
command=python3 /app/scripts/coordinator.py
autorestart=true
# Serves API on port 5005 (polled by the dashboard)

[program:updater]
# One-shot background updater: pulls latest commits and reinstalls only if requirements changed
command=bash /app/scripts/updater.sh
autostart=true
autorestart=false
startsecs=0
startretries=0